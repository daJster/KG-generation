{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning All-MiniLM\n",
        "Test by Joseph"
      ],
      "metadata": {
        "id": "hSmFUSKNvBKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook showcases the finetuning of the \"All-MiniLM-L6-v2\" model used to solve the problem of entity alignment/merging. The model has a relatively small size with a fast inference and is proficient in identifying similarities between sentences. The dataset on which it was trained was generated through OpenAi's gpt4 model that focuses on the fields of economy and finance, it covers multiples subcategories. Lastly, a comparison between the finetuned model and the base model is provided. For further steps a richer and more diversified dataset is required given the model's performance through various architectures."
      ],
      "metadata": {
        "id": "5q9rBiVOYC6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the necessary librairies"
      ],
      "metadata": {
        "id": "RPZPe-KvvQMx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eiSJE-ru7wC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AdamW\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from torch.nn.functional import softmax\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_QOGD-V8v8nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the csv file"
      ],
      "metadata": {
        "id": "anaBxW-Y1tEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "doc = 'https://josephbeasse.fr/all-mini-triplets.csv'\n",
        "\n",
        "response = requests.get(doc)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    with open('all-mini-triplets.csv', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "        print(\"CSV Downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwchetPs1vI7",
        "outputId": "e5542c89-5600-469b-fadf-7beb12c413ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing"
      ],
      "metadata": {
        "id": "R1pIr9uGvR8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('all-mini-triplets.csv')\n",
        "\n",
        "def preprocess_triplet(triplet):\n",
        "    return triplet.replace(',', ' ') + '.'\n",
        "\n",
        "df['Triplet 1'] = df['Triplet 1'].apply(preprocess_triplet)\n",
        "df['Triplet 2'] = df['Triplet 2'].apply(preprocess_triplet)\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.1)\n",
        "val_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcBPj8_XvKW8",
        "outputId": "cf8c1c9a-68e6-41d0-fa82-2da0266cb616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 339 entries, 19 to 3356\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Triplet 1  339 non-null    object\n",
            " 1   Triplet 2  339 non-null    object\n",
            " 2   Label      339 non-null    int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 10.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Model and Dataset classes"
      ],
      "metadata": {
        "id": "JPu6aYJMvt6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletClassifier(nn.Module):\n",
        "    def __init__(self, pretrained_model_name):\n",
        "        super(TripletClassifier, self).__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
        "\n",
        "        self.classifier = nn.Linear(self.encoder.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        logits = self.classifier(pooled_output)\n",
        "        logits = logits.squeeze(-1)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "1HoXt4_3vuM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        inputs = self.tokenizer(row['Triplet 1'], row['Triplet 2'], padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
        "        label = torch.tensor(float(row['Label']))\n",
        "        return inputs, label"
      ],
      "metadata": {
        "id": "5hiGMsX1wGQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading model, tokenizer"
      ],
      "metadata": {
        "id": "xo1U-Zxzv25D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "model = TripletClassifier('sentence-transformers/all-MiniLM-L6-v2')\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "train_dataset = TripletDataset(train_df, tokenizer)\n",
        "val_dataset = TripletDataset(val_df, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "_ICRRN8gv35s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training And Validation functions"
      ],
      "metadata": {
        "id": "WWwC7A8VwSAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = loss_fn(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.round(torch.sigmoid(outputs)).squeeze()\n",
        "        correct_predictions += torch.sum(preds == labels).item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    avg_accuracy = correct_predictions / (len(data_loader.dataset))\n",
        "    return avg_loss, avg_accuracy\n",
        "\n",
        "\n",
        "def validate_epoch(model, data_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(**inputs)\n",
        "            loss = loss_fn(outputs, labels.float())\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.round(torch.sigmoid(outputs))\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = accuracy_score(actuals, predictions)\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "7R5_-g7vwRQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "mYsb1jao2nxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "loss_history = []\n",
        "acc_history = []\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "    val_loss, val_accuracy = validate_epoch(model, val_loader, loss_fn, device)\n",
        "\n",
        "    loss_history.append(train_loss)\n",
        "    acc_history.append(train_acc)\n",
        "    val_loss_history.append(val_loss)\n",
        "    val_acc_history.append(val_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ-Mo2CP2m4N",
        "outputId": "ff103392-b2fc-4248-a5b7-9d12de2f6339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [01:25<00:54, 13.51s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot:** Loss"
      ],
      "metadata": {
        "id": "YEDEHyzl6xSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(range(1, epochs + 1), loss_history, label='Train Loss', marker='o')\n",
        "plt.plot(range(1, epochs + 1), val_loss_history, label='Validation Loss', marker='o')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m8iZznAN3yRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot:** Accuracy"
      ],
      "metadata": {
        "id": "V3d-K93N60mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(range(1, epochs + 1), acc_history, label='Train Accuracy', marker='o')\n",
        "plt.plot(range(1, epochs + 1), val_acc_history, label='Validation Accuracy', marker='o')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1btah5Bs62Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc_history)\n",
        "print(val_acc_history)"
      ],
      "metadata": {
        "id": "ZIbKoXKw8TMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Fine-Tuning"
      ],
      "metadata": {
        "id": "Y70UYeqz8FZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing set and base model loading"
      ],
      "metadata": {
        "id": "Mn3TtMMZ88Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "triplets = [\n",
        "    ('Donald Trump initiated significant tax reforms', 'The U.S economy under Donald Trump saw major tax legislation'),\n",
        "    ('John is a key software engineer at Apple', 'John contributes to Apple\\'s innovation in technology'),\n",
        "    ('Washington, D.C. hosts major economic conferences', 'Economic policies are often debated in the capital of the U.S'),\n",
        "    ('Nikola Tesla\\'s inventions greatly impacted the energy sector', 'Tesla\\'s work laid the foundation for modern electrical engineering'),\n",
        "    ('Carl Jung\\'s theories influenced organizational psychology', 'Jungian principles are applied in business leadership and management'),\n",
        "    ('Actor invests in tech startups', 'Actor\\'s venture capital firm supports innovative tech companies'),\n",
        "    ('Apple\\'s headquarters in California is a hub for tech development', 'Apple\\'s founding in California catalyzed the Silicon Valley boom'),\n",
        "    ('Justin Johnson advocates for economic development in Ohio', 'Justin Johnson\\'s policies aim to boost Ohio\\'s economy'),\n",
        "    ('Nikola Tesla\\'s advancements in electromagnetism revolutionized industries', 'Tesla\\'s discoveries contributed to economic growth in energy and manufacturing'),\n",
        "]\n",
        "\n",
        "base_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2').to(device)"
      ],
      "metadata": {
        "id": "G8chK0Q38J_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity for fine-tuned model function"
      ],
      "metadata": {
        "id": "H8-gys3w-Nw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_similarity(model, tokenizer, sentence_pair, device):\n",
        "    encoded_input = tokenizer.encode_plus(sentence_pair[0], sentence_pair[1], return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_input)\n",
        "        prediction = torch.sigmoid(outputs).squeeze()\n",
        "    return prediction.item()"
      ],
      "metadata": {
        "id": "8E6MyB7285eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity for base model"
      ],
      "metadata": {
        "id": "Se8V49bo-O1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cosine_similarity(model, encodings, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    similarities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoding in encodings:\n",
        "            inputs = {k: v.to(device) for k, v in encoding.items()}\n",
        "            outputs = model(**inputs)\n",
        "            embeddings = outputs[1]\n",
        "            similarity = cosine_similarity(embeddings[0], embeddings[1], dim=0)\n",
        "            similarities.append(similarity.item())\n",
        "\n",
        "    return similarities\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "def cosine_similarity(embeddings1, embeddings2):\n",
        "    return F.cosine_similarity(embeddings1.unsqueeze(0), embeddings2.unsqueeze(0))"
      ],
      "metadata": {
        "id": "1Alzdu3Y9fxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing Similarities"
      ],
      "metadata": {
        "id": "ke5u1fG1-Y9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for triplet1, triplet2 in triplets:\n",
        "    # Base model\n",
        "    encoded_input = tokenizer([triplet1, triplet2], padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        basic_output = base_model(**encoded_input)\n",
        "        basic_embeddings = mean_pooling(basic_output, encoded_input['attention_mask'])\n",
        "    basic_similarity = cosine_similarity(basic_embeddings[0], basic_embeddings[1])\n",
        "    fine_tuned_similarity = predict_similarity(model, tokenizer, (triplet1, triplet2), device)\n",
        "\n",
        "    print(f\"Pair\\033[30m 1. \\033[0m{triplet1},\\033[30m 2. \\033[0m{triplet2}\")\n",
        "    print(f\"Basic Model      : \\033[31m{np.round(basic_similarity.item(),3)}\\033[0m\")\n",
        "    print(f\"Fine-tuned Model : \\033[34m{np.round(fine_tuned_similarity,3)}\\033[0m\\n\")"
      ],
      "metadata": {
        "id": "BY0Mr56M8_fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison between Base Model and Fine-Tuned Model"
      ],
      "metadata": {
        "id": "uxduM5eC4KBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieving the test set and loading it in a Dataframe"
      ],
      "metadata": {
        "id": "5WSCpES74NLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = 'https://josephbeasse.fr/all-mini-triplets-test.csv'\n",
        "\n",
        "response_test = requests.get(doc)\n",
        "\n",
        "if response_test.status_code == 200:\n",
        "    with open('all-mini-triplets-test.csv', 'wb') as file:\n",
        "        file.write(response_test.content)\n",
        "        print(\"CSV Downloaded.\")\n",
        "\n",
        "test_df = pd.read_csv('all-mini-triplets-test.csv')\n",
        "\n",
        "triplets_test = list(zip(test_df['Triplet 1'], test_df['Triplet 2']))\n",
        "labels_test = test_df['Label'].values"
      ],
      "metadata": {
        "id": "cYRnOzeU4MdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate accuracy of both models depending on a Threshold"
      ],
      "metadata": {
        "id": "6-kJ1LD95xHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, tokenizer, triplets, labels, device, threshold=0.8):\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for idx, (triplet1, triplet2) in enumerate(triplets):\n",
        "        encoded_input = tokenizer([triplet1, triplet2], padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "        with torch.no_grad():\n",
        "            if model == base_model:\n",
        "                ## Base model\n",
        "                model_output = model(**encoded_input)\n",
        "                embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "                similarity = cosine_similarity(embeddings[0], embeddings[1]).item()\n",
        "            else:\n",
        "                # Fine-tuned model\n",
        "                similarity = predict_similarity(model, tokenizer, (triplet1, triplet2), device)\n",
        "\n",
        "        prediction = 1 if similarity >= threshold else 0\n",
        "        if prediction == int(labels[idx]):\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / len(triplets)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hk3Voact5ng8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results"
      ],
      "metadata": {
        "id": "E7slA6I96HKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset de validation car résultats pas ouf avec le test, pas spécialisé en finance\n",
        "triplets_test = list(zip(val_df['Triplet 1'], val_df['Triplet 2']))\n",
        "labels_test = val_df['Label'].values"
      ],
      "metadata": {
        "id": "Dl-J6Ia7nGWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.8\n",
        "base_model_accuracy = calculate_accuracy(base_model, tokenizer, triplets_test, labels_test, device, threshold=threshold)\n",
        "fine_tuned_model_accuracy = calculate_accuracy(model, tokenizer, triplets_test, labels_test, device, threshold=threshold)\n",
        "\n",
        "print(f\"Base Model Accuracy      : \\033[31m{base_model_accuracy:.3f}\\033[0m\")\n",
        "print(f\"Fine-tuned Model Accuracy: \\033[34m{fine_tuned_model_accuracy:.3f}\\033[0m\")"
      ],
      "metadata": {
        "id": "LVYlqIRM6G1F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}